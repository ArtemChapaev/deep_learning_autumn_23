{
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 7007774,
     "sourceType": "datasetVersion",
     "datasetId": 4028749
    }
   ],
   "dockerImageVersionId": 30587,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/KuzmaKhrabrov/character-tokenizer.git\n",
    "!pip install transformers"
   ],
   "metadata": {
    "id": "5HmwpqzwnMyE",
    "execution": {
     "iopub.status.busy": "2023-12-05T12:18:25.020636Z",
     "iopub.execute_input": "2023-12-05T12:18:25.021406Z",
     "iopub.status.idle": "2023-12-05T12:18:37.484088Z",
     "shell.execute_reply.started": "2023-12-05T12:18:25.021373Z",
     "shell.execute_reply": "2023-12-05T12:18:37.482863Z"
    },
    "trusted": true
   },
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "text": "fatal: destination path 'character-tokenizer' already exists and is not an empty directory.\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"/kaggle/working/character-tokenizer\")\n",
    "from charactertokenizer import CharacterTokenizer"
   ],
   "metadata": {
    "id": "5FaCG9ajnS_G",
    "execution": {
     "iopub.status.busy": "2023-12-05T12:18:37.486616Z",
     "iopub.execute_input": "2023-12-05T12:18:37.487029Z",
     "iopub.status.idle": "2023-12-05T12:18:37.492804Z",
     "shell.execute_reply.started": "2023-12-05T12:18:37.486992Z",
     "shell.execute_reply": "2023-12-05T12:18:37.491668Z"
    },
    "trusted": true
   },
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "device"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:18:37.493921Z",
     "iopub.execute_input": "2023-12-05T12:18:37.494227Z",
     "iopub.status.idle": "2023-12-05T12:18:37.507422Z",
     "shell.execute_reply.started": "2023-12-05T12:18:37.494197Z",
     "shell.execute_reply": "2023-12-05T12:18:37.506502Z"
    },
    "trusted": true
   },
   "execution_count": 67,
   "outputs": [
    {
     "execution_count": 67,
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n",
    "model_max_length = 64\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 4\n",
    "seed_val = 42"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:18:44.153598Z",
     "iopub.execute_input": "2023-12-05T12:18:44.153994Z",
     "iopub.status.idle": "2023-12-05T12:18:44.158863Z",
     "shell.execute_reply.started": "2023-12-05T12:18:44.153961Z",
     "shell.execute_reply": "2023-12-05T12:18:44.157862Z"
    },
    "trusted": true
   },
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = CharacterTokenizer(chars, model_max_length)\n",
    "example = \"Привет\"\n",
    "tokens = tokenizer(example)\n",
    "tokens"
   ],
   "metadata": {
    "id": "I5FSPMOSncpI",
    "execution": {
     "iopub.status.busy": "2023-12-05T06:22:47.304021Z",
     "iopub.execute_input": "2023-12-05T06:22:47.304361Z",
     "iopub.status.idle": "2023-12-05T06:22:47.318101Z",
     "shell.execute_reply.started": "2023-12-05T06:22:47.304330Z",
     "shell.execute_reply": "2023-12-05T06:22:47.317343Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Задание: обучите модель классификации букв для задачи расстановки ударения с помощью методов из библиотеки transformers. Датасет для обучения можно взять отсюда: https://github.com/Koziev/NLP_Datasets/blob/master/Stress/all_accents.zip\n",
    "\n",
    "1. Напишите класс для Dataset/Dataloder и разбейте данные на случайные train / test сплиты в соотношении 50:50. (1 балл)\n",
    "2. Попробуйте обучить одну или несколько из моделей: Bert, Albert, Deberta. Посчитайте метрику Accuracy на train и test. (1 балл). При преодолении порога в Accuracy на test 0.8: (+1 балл), 0.85: (+2 балла), 0.89: (+3 балла).\n",
    "Пример конфигурации для deberta: https://huggingface.co/IlyaGusev/ru-word-stress-transformer/blob/main/config.json"
   ],
   "metadata": {
    "id": "KQkp36rEoScR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_table('/kaggle/input/hw10-wordstress/all_accents.tsv', header=None, names = ['word', 'stressed_word'])\n",
    "df['stress_idx'] = df['stressed_word'].str.find('^')\n",
    "\n",
    "# model_max_length = df['word'].apply(lambda x: len(x)).max() + 2\n",
    "# model_max_length"
   ],
   "metadata": {
    "id": "mRVK6TNAZQFk",
    "execution": {
     "iopub.status.busy": "2023-12-05T06:22:47.319211Z",
     "iopub.execute_input": "2023-12-05T06:22:47.319476Z",
     "iopub.status.idle": "2023-12-05T06:22:53.114704Z",
     "shell.execute_reply.started": "2023-12-05T06:22:47.319454Z",
     "shell.execute_reply": "2023-12-05T06:22:53.113886Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.5, random_state=seed_val)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.2, random_state=seed_val)\n",
    "\n",
    "train_df.shape[0], val_df.shape[0], test_df.shape[0]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:22:53.115791Z",
     "iopub.execute_input": "2023-12-05T06:22:53.116083Z",
     "iopub.status.idle": "2023-12-05T06:22:54.120690Z",
     "shell.execute_reply.started": "2023-12-05T06:22:53.116058Z",
     "shell.execute_reply": "2023-12-05T06:22:54.119808Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class WordStressDataset(Dataset):\n",
    "    def __init__(self, df, max_len):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = CharacterTokenizer(chars, model_max_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.df['word'].iloc[idx]\n",
    "        stress_idx = self.df['stress_idx'].iloc[idx]\n",
    "\n",
    "        tokens = self.tokenizer(\n",
    "            word,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        labels = torch.zeros((self.max_len), dtype=torch.long)\n",
    "        if stress_idx > 0:\n",
    "            labels[stress_idx] = 1\n",
    "        \n",
    "        return tokens['input_ids'].flatten(), tokens['attention_mask'].flatten(), labels"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:22:54.121842Z",
     "iopub.execute_input": "2023-12-05T06:22:54.122151Z",
     "iopub.status.idle": "2023-12-05T06:22:54.130071Z",
     "shell.execute_reply.started": "2023-12-05T06:22:54.122127Z",
     "shell.execute_reply": "2023-12-05T06:22:54.129150Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = WordStressDataset(train_df, model_max_length)\n",
    "val_dataset = WordStressDataset(val_df, model_max_length)\n",
    "test_dataset = WordStressDataset(test_df, model_max_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:22:54.131322Z",
     "iopub.execute_input": "2023-12-05T06:22:54.131644Z",
     "iopub.status.idle": "2023-12-05T06:22:54.147884Z",
     "shell.execute_reply.started": "2023-12-05T06:22:54.131614Z",
     "shell.execute_reply": "2023-12-05T06:22:54.146914Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import DebertaV2ForTokenClassification, AdamW, DebertaV2Config, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "config = DebertaV2Config(\n",
    "    architectures=\"DebertaV2ForTokenClassification\",\n",
    "    model_type=\"deberta-v2\",\n",
    "    transformers_version=\"4.25.1\",\n",
    "    torch_dtype=\"float32\",\n",
    "    \n",
    "    num_labels=2,\n",
    "\n",
    "    hidden_size=1024,\n",
    "    intermediate_size=2048,\n",
    "    num_attention_heads=16,\n",
    "    num_hidden_layers=5,\n",
    "    \n",
    "    hidden_dropout_prob=0.2,\n",
    "    attention_probs_dropout_prob=0.2,\n",
    "    position_biased_input=True,\n",
    "    \n",
    "    vocab_size=len(tokenizer.get_vocab()),\n",
    "    \n",
    "    max_length=model_max_length,\n",
    "    max_position_embeddings=model_max_length,\n",
    "    max_relative_positions=model_max_length,\n",
    "    \n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,    \n",
    "    \n",
    "    #initializer_range=0.02,\n",
    "    pooler_dropout = 0,\n",
    "    pooler_hidden_act = \"gelu\",\n",
    "    pooler_hidden_size = 1536\n",
    ")\n",
    "\n",
    "model = DebertaV2ForTokenClassification(config)\n",
    "\n",
    "model.cuda()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:22:54.151016Z",
     "iopub.execute_input": "2023-12-05T06:22:54.151394Z",
     "iopub.status.idle": "2023-12-05T06:22:58.648540Z",
     "shell.execute_reply.started": "2023-12-05T06:22:54.151361Z",
     "shell.execute_reply": "2023-12-05T06:22:58.647450Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 1e-5,\n",
    "    eps = 1e-8,\n",
    ")\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = total_steps,\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:22:58.649823Z",
     "iopub.execute_input": "2023-12-05T06:22:58.650345Z",
     "iopub.status.idle": "2023-12-05T06:22:58.660736Z",
     "shell.execute_reply.started": "2023-12-05T06:22:58.650313Z",
     "shell.execute_reply": "2023-12-05T06:22:58.659863Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:23:07.241846Z",
     "iopub.execute_input": "2023-12-05T06:23:07.242209Z",
     "iopub.status.idle": "2023-12-05T06:23:07.246516Z",
     "shell.execute_reply.started": "2023-12-05T06:23:07.242180Z",
     "shell.execute_reply": "2023-12-05T06:23:07.245598Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def flat_accuracy(preds, labels):    \n",
    "    return np.all(preds == labels, axis=1).sum() / len(labels)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:23:07.583718Z",
     "iopub.execute_input": "2023-12-05T06:23:07.584535Z",
     "iopub.status.idle": "2023-12-05T06:23:07.589066Z",
     "shell.execute_reply.started": "2023-12-05T06:23:07.584502Z",
     "shell.execute_reply": "2023-12-05T06:23:07.588077Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:23:07.956371Z",
     "iopub.execute_input": "2023-12-05T06:23:07.956986Z",
     "iopub.status.idle": "2023-12-05T06:23:07.961239Z",
     "shell.execute_reply.started": "2023-12-05T06:23:07.956960Z",
     "shell.execute_reply": "2023-12-05T06:23:07.960224Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "count_logging_elapsed = 10"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:23:08.435847Z",
     "iopub.execute_input": "2023-12-05T06:23:08.436570Z",
     "iopub.status.idle": "2023-12-05T06:23:08.440482Z",
     "shell.execute_reply.started": "2023-12-05T06:23:08.436537Z",
     "shell.execute_reply": "2023-12-05T06:23:08.439530Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(epoch_i):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % int(len(train_dataloader) / (count_logging_elapsed)) == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "\n",
    "    print(\"\")\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    \n",
    "    train_time = format_time(time.time() - t0)\n",
    "    print(\"  Training epoch took: {:}\".format(train_time))\n",
    "    \n",
    "    return avg_train_loss, train_time"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:23:08.712605Z",
     "iopub.execute_input": "2023-12-05T06:23:08.713227Z",
     "iopub.status.idle": "2023-12-05T06:23:08.721853Z",
     "shell.execute_reply.started": "2023-12-05T06:23:08.713197Z",
     "shell.execute_reply": "2023-12-05T06:23:08.721087Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def validate():\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    \n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels\n",
    "            )\n",
    "    \n",
    "        loss = outputs.loss\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = torch.argmax(outputs.logits.detach(), dim=2).cpu().numpy()\n",
    "        \n",
    "        label_ids = b_labels.cpu().numpy()\n",
    "        \n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    \n",
    "    val_time = format_time(time.time() - t0)\n",
    "    print(\"  Validation took: {:}\".format(val_time))\n",
    "    \n",
    "    return avg_val_loss, avg_val_accuracy, val_time"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:23:09.058771Z",
     "iopub.execute_input": "2023-12-05T06:23:09.059354Z",
     "iopub.status.idle": "2023-12-05T06:23:09.069468Z",
     "shell.execute_reply.started": "2023-12-05T06:23:09.059325Z",
     "shell.execute_reply": "2023-12-05T06:23:09.068438Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "train_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    model.train()\n",
    "    avg_train_loss, train_time = train(epoch_i)\n",
    "\n",
    "    model.eval()\n",
    "    avg_val_loss, avg_val_accuracy, val_time = validate()\n",
    "\n",
    "    train_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': train_time,\n",
    "            'Validation Time': val_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T06:23:09.487083Z",
     "iopub.execute_input": "2023-12-05T06:23:09.487412Z",
     "iopub.status.idle": "2023-12-05T09:27:27.228353Z",
     "shell.execute_reply.started": "2023-12-05T06:23:09.487384Z",
     "shell.execute_reply": "2023-12-05T09:27:27.227312Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_stats = pd.DataFrame(data=train_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "df_stats"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T09:27:27.230556Z",
     "iopub.execute_input": "2023-12-05T09:27:27.231292Z",
     "iopub.status.idle": "2023-12-05T09:27:27.249382Z",
     "shell.execute_reply.started": "2023-12-05T09:27:27.231233Z",
     "shell.execute_reply": "2023-12-05T09:27:27.248532Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как видно лосс на валидационной выборке падает, поэтому запустим еще на две итерацию"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "avg_train_loss, train_time = train(4)\n",
    "\n",
    "model.eval()\n",
    "avg_val_loss, avg_val_accuracy, val_time = validate()\n",
    "\n",
    "train_stats.append(\n",
    "    {\n",
    "        'epoch': epoch_i + 1,\n",
    "        'Training Loss': avg_train_loss,\n",
    "        'Valid. Loss': avg_val_loss,\n",
    "        'Valid. Accur.': avg_val_accuracy,\n",
    "        'Training Time': train_time,\n",
    "        'Validation Time': val_time\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T09:29:57.264750Z",
     "iopub.execute_input": "2023-12-05T09:29:57.265478Z",
     "iopub.status.idle": "2023-12-05T10:16:05.766291Z",
     "shell.execute_reply.started": "2023-12-05T09:29:57.265445Z",
     "shell.execute_reply": "2023-12-05T10:16:05.765233Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "avg_train_loss, train_time = train(5)\n",
    "\n",
    "model.eval()\n",
    "avg_val_loss, avg_val_accuracy, val_time = validate()\n",
    "\n",
    "train_stats.append(\n",
    "    {\n",
    "        'epoch': epoch_i + 1,\n",
    "        'Training Loss': avg_train_loss,\n",
    "        'Valid. Loss': avg_val_loss,\n",
    "        'Valid. Accur.': avg_val_accuracy,\n",
    "        'Training Time': train_time,\n",
    "        'Validation Time': val_time\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T10:31:26.880103Z",
     "iopub.execute_input": "2023-12-05T10:31:26.880920Z",
     "iopub.status.idle": "2023-12-05T11:17:37.829458Z",
     "shell.execute_reply.started": "2023-12-05T10:31:26.880885Z",
     "shell.execute_reply": "2023-12-05T11:17:37.828532Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_stats"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:19:03.570109Z",
     "iopub.execute_input": "2023-12-05T12:19:03.570883Z",
     "iopub.status.idle": "2023-12-05T12:19:03.583750Z",
     "shell.execute_reply.started": "2023-12-05T12:19:03.570850Z",
     "shell.execute_reply": "2023-12-05T12:19:03.582821Z"
    },
    "trusted": true
   },
   "execution_count": 73,
   "outputs": [
    {
     "execution_count": 73,
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\nepoch                                                                         \n1           0.019774     0.013858       0.775947       0:42:51         0:03:16\n2           0.013193     0.010349       0.833933       0:42:49         0:03:17\n3           0.010828     0.008581       0.865191       0:42:49         0:03:15\n4           0.009258     0.007619       0.884320       0:42:46         0:03:15\n4           0.008158     0.006536       0.898526       0:42:52         0:03:17\n4           0.007316     0.005819       0.911593       0:42:55         0:03:16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Training Loss</th>\n      <th>Valid. Loss</th>\n      <th>Valid. Accur.</th>\n      <th>Training Time</th>\n      <th>Validation Time</th>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.019774</td>\n      <td>0.013858</td>\n      <td>0.775947</td>\n      <td>0:42:51</td>\n      <td>0:03:16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.013193</td>\n      <td>0.010349</td>\n      <td>0.833933</td>\n      <td>0:42:49</td>\n      <td>0:03:17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.010828</td>\n      <td>0.008581</td>\n      <td>0.865191</td>\n      <td>0:42:49</td>\n      <td>0:03:15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.009258</td>\n      <td>0.007619</td>\n      <td>0.884320</td>\n      <td>0:42:46</td>\n      <td>0:03:15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.008158</td>\n      <td>0.006536</td>\n      <td>0.898526</td>\n      <td>0:42:52</td>\n      <td>0:03:17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.007316</td>\n      <td>0.005819</td>\n      <td>0.911593</td>\n      <td>0:42:55</td>\n      <td>0:03:16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def test():\n",
    "    predictions , true_labels = [], []\n",
    "    \n",
    "    total_test_accuracy = 0\n",
    "    \n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                b_input_ids, \n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "            )\n",
    "             \n",
    "        logits = torch.argmax(outputs.logits.detach(), dim=2).cpu().numpy()\n",
    "        label_ids = b_labels.cpu().numpy()\n",
    "        total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
    "    \n",
    "    return avg_test_accuracy, predictions, true_labels"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:19:34.718996Z",
     "iopub.execute_input": "2023-12-05T12:19:34.719892Z",
     "iopub.status.idle": "2023-12-05T12:19:34.726697Z",
     "shell.execute_reply.started": "2023-12-05T12:19:34.719858Z",
     "shell.execute_reply": "2023-12-05T12:19:34.725699Z"
    },
    "trusted": true
   },
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "avg_test_accuracy, predictions, true_labels = test()\n",
    "\n",
    "print(f'{avg_test_accuracy}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:19:34.924905Z",
     "iopub.execute_input": "2023-12-05T12:19:34.925153Z",
     "iopub.status.idle": "2023-12-05T12:32:32.927059Z",
     "shell.execute_reply.started": "2023-12-05T12:19:34.925132Z",
     "shell.execute_reply": "2023-12-05T12:32:32.926083Z"
    },
    "trusted": true
   },
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "text": "0.9110370021377138\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "batch = next(iter(test_dataloader))\n",
    "b_input_ids = batch[0].to(device)\n",
    "b_input_mask = batch[1].to(device)\n",
    "b_labels = batch[2]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        b_input_ids, \n",
    "        token_type_ids=None,\n",
    "        attention_mask=b_input_mask,\n",
    "    )\n",
    "\n",
    "logits = torch.argmax(outputs.logits.detach(), dim=2).cpu().numpy()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:32:32.928886Z",
     "iopub.execute_input": "2023-12-05T12:32:32.929190Z",
     "iopub.status.idle": "2023-12-05T12:32:33.011582Z",
     "shell.execute_reply.started": "2023-12-05T12:32:32.929164Z",
     "shell.execute_reply": "2023-12-05T12:32:33.010803Z"
    },
    "trusted": true
   },
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\".join(map(lambda x: x if x != '[PAD]' else \"\", tokenizer.convert_ids_to_tokens(b_input_ids[0]))))\n",
    "print(f\"actual: {np.where(logits[0] == 1)[0]}, expected: {np.where(b_labels[0].numpy() == 1)[0]}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:32:33.012649Z",
     "iopub.execute_input": "2023-12-05T12:32:33.012933Z",
     "iopub.status.idle": "2023-12-05T12:32:33.020573Z",
     "shell.execute_reply.started": "2023-12-05T12:32:33.012910Z",
     "shell.execute_reply": "2023-12-05T12:32:33.019626Z"
    },
    "trusted": true
   },
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "text": "[CLS]вскрывающей[SEP]\nactual: [6], expected: [6]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\".join(map(lambda x: x if x != '[PAD]' else \"\", tokenizer.convert_ids_to_tokens(b_input_ids[1]))))\n",
    "print(f\"actual: {np.where(logits[1] == 1)[0]}, expected: {np.where(b_labels[1].numpy() == 1)[0]}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:32:33.022475Z",
     "iopub.execute_input": "2023-12-05T12:32:33.022748Z",
     "iopub.status.idle": "2023-12-05T12:32:33.030941Z",
     "shell.execute_reply.started": "2023-12-05T12:32:33.022724Z",
     "shell.execute_reply": "2023-12-05T12:32:33.030009Z"
    },
    "trusted": true
   },
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "text": "[CLS]добропорядошный[SEP]\nactual: [8], expected: [8]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\".join(map(lambda x: x if x != '[PAD]' else \"\", tokenizer.convert_ids_to_tokens(b_input_ids[2]))))\n",
    "print(f\"actual: {np.where(logits[2] == 1)[0]}, expected: {np.where(b_labels[2].numpy() == 1)[0]}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-05T12:32:33.032117Z",
     "iopub.execute_input": "2023-12-05T12:32:33.032405Z",
     "iopub.status.idle": "2023-12-05T12:32:33.041622Z",
     "shell.execute_reply.started": "2023-12-05T12:32:33.032382Z",
     "shell.execute_reply": "2023-12-05T12:32:33.040655Z"
    },
    "trusted": true
   },
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "text": "[CLS]мыслившего[SEP]\nactual: [1], expected: [1]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Таким образом, наша модель достаточно хорошо проставляет ударения"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
