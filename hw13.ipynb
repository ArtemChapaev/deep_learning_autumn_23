{
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torch-geometric\n",
    "!pip install sentence_transformers"
   ],
   "metadata": {
    "id": "GJaiF8Lby2Dm",
    "execution": {
     "iopub.status.busy": "2023-12-21T09:31:28.912877Z",
     "iopub.execute_input": "2023-12-21T09:31:28.913249Z",
     "iopub.status.idle": "2023-12-21T09:32:03.330841Z",
     "shell.execute_reply.started": "2023-12-21T09:31:28.913217Z",
     "shell.execute_reply": "2023-12-21T09:32:03.329647Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting torch-geometric\n  Obtaining dependency information for torch-geometric from https://files.pythonhosted.org/packages/65/4e/6f9a75548a93fedcd4514ae2de9bee1e91bade6b73252b4da32f0e42ac52/torch_geometric-2.4.0-py3-none-any.whl.metadata\n  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.9/63.9 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.24.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.4)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.31.0)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2023.11.17)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\nDownloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m17.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n\u001B[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.4.0\nCollecting sentence_transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.0/86.0 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\n\u001B[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.36.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.24.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (10.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\nBuilding wheels for collected packages: sentence_transformers\n  Building wheel for sentence_transformers (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=d13612361939d49dfbe40f82d12ec46f3420bc4a6be8cd5b90237d8ab8fea03a\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence_transformers\nInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-2.2.2\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.nn import GATConv, SAGEConv, to_hetero\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "MYtBy-ZGy7lb",
    "execution": {
     "iopub.status.busy": "2023-12-21T09:57:00.616660Z",
     "iopub.execute_input": "2023-12-21T09:57:00.617084Z",
     "iopub.status.idle": "2023-12-21T09:57:00.623252Z",
     "shell.execute_reply.started": "2023-12-21T09:57:00.617052Z",
     "shell.execute_reply": "2023-12-21T09:57:00.622135Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = '/tmp/'\n",
    "dataset = MovieLens(root=dataset_path)"
   ],
   "metadata": {
    "id": "IsDp2bXpy7n-",
    "execution": {
     "iopub.status.busy": "2023-12-21T09:32:10.142874Z",
     "iopub.execute_input": "2023-12-21T09:32:10.143371Z",
     "iopub.status.idle": "2023-12-21T09:32:24.903365Z",
     "shell.execute_reply.started": "2023-12-21T09:32:10.143339Z",
     "shell.execute_reply": "2023-12-21T09:32:24.902282Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\nExtracting /tmp/raw/ml-latest-small.zip\nProcessing...\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": ".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53b695d970b64078ba192dacc9bce743"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db4b15aa81754f75bc17002e042edd7d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64bf40c2ae9344f4a406db0aed3689bd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f18bfb18c864cebb499df474a66923f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26631f994af7415ca21121aaccda8be9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "643eab73c68242418f6b364471621a42"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d70bca454539417c9df5f32554f5d1ef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1237a5362f484fd6b5346e12d10914f5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d51bf2620a4640e190d900724cb9cd9c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c3d9b96dc2943298bf078c3d5b2afa7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fdd3b6c4feb46b8b3b882180dbc5a73"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d87018767d4411eb2be02c3292d048e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5131789c00446c5bab482d0d944eee2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17a9d26619d4472bb9d451f8d6817712"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Batches:   0%|          | 0/305 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7b52774a6a945288d202889d658f0e2"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "Done!\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "id": "tG06N0CB28S2",
    "execution": {
     "iopub.status.busy": "2023-12-21T09:38:40.592083Z",
     "iopub.execute_input": "2023-12-21T09:38:40.593104Z",
     "iopub.status.idle": "2023-12-21T09:38:40.598323Z",
     "shell.execute_reply.started": "2023-12-21T09:38:40.593064Z",
     "shell.execute_reply": "2023-12-21T09:38:40.597212Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "# Add user node features for message passing:\n",
    "data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n",
    "del data['user'].num_nodes\n",
    "\n",
    "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
    "data = T.ToUndirected()(data)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "\n",
    "# Perform a link-level split into training, validation, and test edges:\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")(data)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-21T09:38:40.961315Z",
     "iopub.execute_input": "2023-12-21T09:38:40.962219Z",
     "iopub.status.idle": "2023-12-21T09:38:40.980567Z",
     "shell.execute_reply.started": "2023-12-21T09:38:40.962182Z",
     "shell.execute_reply": "2023-12-21T09:38:40.979447Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "weight = torch.bincount(train_data['user', 'movie'].edge_label)\n",
    "weight = weight.max() / weight\n",
    "\n",
    "weight"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-21T09:38:41.713588Z",
     "iopub.execute_input": "2023-12-21T09:38:41.714001Z",
     "iopub.status.idle": "2023-12-21T09:38:41.723835Z",
     "shell.execute_reply.started": "2023-12-21T09:38:41.713970Z",
     "shell.execute_reply": "2023-12-21T09:38:41.722742Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([26.2224,  7.6305,  2.6939,  1.0637,  1.0000,  2.6983], device='cuda:0')"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def weighted_mse_loss(pred, target, weight=None):\n",
    "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
   ],
   "metadata": {
    "id": "YNw0WPkl0jai",
    "execution": {
     "iopub.status.busy": "2023-12-21T09:41:33.736414Z",
     "iopub.execute_input": "2023-12-21T09:41:33.736853Z",
     "iopub.status.idle": "2023-12-21T09:41:33.754868Z",
     "shell.execute_reply.started": "2023-12-21T09:41:33.736821Z",
     "shell.execute_reply": "2023-12-21T09:41:33.753626Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание\n",
    "\n",
    "1) Подберите оптимальные параметры для сети из примера выше(2 балла)\n",
    "\n",
    "2) Попробуйте вместо GraphSage модуль Graph Attention и также подберите оптимальные параметры  (2 балла)\n"
   ],
   "metadata": {
    "id": "uCuIyDT57GoX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 1\n",
    "\n",
    "Добавим еще один линейный слой в EdgeDecoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z).relu()\n",
    "        z = self.lin3(z)\n",
    "        return z.view(-1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-21T09:53:26.987927Z",
     "iopub.execute_input": "2023-12-21T09:53:26.989109Z",
     "iopub.status.idle": "2023-12-21T09:53:26.998968Z",
     "shell.execute_reply.started": "2023-12-21T09:53:26.989066Z",
     "shell.execute_reply": "2023-12-21T09:53:26.997848Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['user', 'movie'].edge_label_index)\n",
    "    target = train_data['user', 'movie'].edge_label\n",
    "    loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-21T09:53:29.194035Z",
     "iopub.execute_input": "2023-12-21T09:53:29.194513Z",
     "iopub.status.idle": "2023-12-21T09:53:29.205727Z",
     "shell.execute_reply.started": "2023-12-21T09:53:29.194478Z",
     "shell.execute_reply": "2023-12-21T09:53:29.204455Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Увеличим число скрытых каналов, число эпох, немного уменьшим lr оптимизатора"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model = Model(hidden_channels=52).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0075)\n",
    "\n",
    "\n",
    "for epoch in range(1, 351):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "              f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ],
   "metadata": {
    "id": "QApxL66H7EyY",
    "execution": {
     "iopub.status.busy": "2023-12-21T09:46:04.313157Z",
     "iopub.execute_input": "2023-12-21T09:46:04.313838Z",
     "iopub.status.idle": "2023-12-21T09:46:19.212447Z",
     "shell.execute_reply.started": "2023-12-21T09:46:04.313802Z",
     "shell.execute_reply": "2023-12-21T09:46:19.211463Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch: 50, Loss: 3.7455, Train: 1.1498, Val: 1.1483, Test: 1.1554\nEpoch: 100, Loss: 3.0354, Train: 1.1114, Val: 1.1507, Test: 1.1458\nEpoch: 150, Loss: 2.7739, Train: 1.0692, Val: 1.1209, Test: 1.1221\nEpoch: 200, Loss: 2.3681, Train: 1.0287, Val: 1.1001, Test: 1.1096\nEpoch: 250, Loss: 2.2822, Train: 1.0498, Val: 1.1460, Test: 1.1482\nEpoch: 300, Loss: 1.9758, Train: 0.9600, Val: 1.0831, Test: 1.0932\nEpoch: 350, Loss: 1.8657, Train: 0.9121, Val: 1.0535, Test: 1.0636\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получилось добиться результата лучше 1.1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 2\n",
    "\n",
    "Перепишем GNNEncoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), hidden_channels, heads=num_heads, dropout=0.6, add_self_loops=False)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, out_channels, heads=1, dropout=0.6, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z).relu()\n",
    "        z = self.lin3(z)\n",
    "        return z.view(-1)"
   ],
   "metadata": {
    "id": "F1ZQhceb7HQa",
    "execution": {
     "iopub.status.busy": "2023-12-21T09:58:27.129508Z",
     "iopub.execute_input": "2023-12-21T09:58:27.129916Z",
     "iopub.status.idle": "2023-12-21T09:58:27.140554Z",
     "shell.execute_reply.started": "2023-12-21T09:58:27.129886Z",
     "shell.execute_reply": "2023-12-21T09:58:27.139475Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_heads):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels, num_heads)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['user', 'movie'].edge_label_index)\n",
    "    target = train_data['user', 'movie'].edge_label\n",
    "    loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-21T09:58:27.499762Z",
     "iopub.execute_input": "2023-12-21T09:58:27.500168Z",
     "iopub.status.idle": "2023-12-21T09:58:27.511615Z",
     "shell.execute_reply.started": "2023-12-21T09:58:27.500136Z",
     "shell.execute_reply": "2023-12-21T09:58:27.509984Z"
    },
    "trusted": true
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = Model(hidden_channels=32, num_heads=1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "\n",
    "for epoch in range(1, 501):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "              f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-21T10:00:08.334322Z",
     "iopub.execute_input": "2023-12-21T10:00:08.334721Z",
     "iopub.status.idle": "2023-12-21T10:00:20.114971Z",
     "shell.execute_reply.started": "2023-12-21T10:00:08.334693Z",
     "shell.execute_reply": "2023-12-21T10:00:20.113834Z"
    },
    "trusted": true
   },
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch: 50, Loss: 6.5037, Train: 1.3019, Val: 1.3412, Test: 1.3397\nEpoch: 100, Loss: 5.6251, Train: 1.4281, Val: 1.4483, Test: 1.4442\nEpoch: 150, Loss: 5.0196, Train: 1.3554, Val: 1.3720, Test: 1.3772\nEpoch: 200, Loss: 4.7286, Train: 1.2571, Val: 1.2717, Test: 1.2726\nEpoch: 250, Loss: 4.5608, Train: 1.1129, Val: 1.1231, Test: 1.1220\nEpoch: 300, Loss: 4.1985, Train: 1.1592, Val: 1.1668, Test: 1.1622\nEpoch: 350, Loss: 3.9516, Train: 1.0996, Val: 1.1120, Test: 1.1082\nEpoch: 400, Loss: 3.8310, Train: 1.0310, Val: 1.0452, Test: 1.0439\nEpoch: 450, Loss: 3.7637, Train: 1.0905, Val: 1.1034, Test: 1.0983\nEpoch: 500, Loss: 3.7187, Train: 0.9989, Val: 1.0077, Test: 1.0130\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
